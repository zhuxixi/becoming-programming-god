# 深入理解Kafka 0.9.0.1

## 0 基本概念
### 0.1 broker
1. 一个独立的 Kafka 服务器被称为 broker。 
2. broker接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。 
3. broker为消费者提供服务，对读取分区的请求作出响应，返回已经提交到磁盘上的消息。
4. **根据特定的硬件及其性能特征，单个 broker 可以轻松处理数千个分区以及每秒
百万级的消息量。**
### 0.2 集群
1. broker是集群的组成部分。
2. 每个集群都有一个 broker 同时充当了**集群控制器**的角色（自动从集群的活跃成员
中选举出来）。
3. **集群控制器**负责管理工作，包括将分区分配给broker和监控broker。
### 0.3 分区
1. 在集群中，一个分区从属于一个broker，该broker被称为**分区的首领**。
2. 一个分区可以分配给多个 broker，这个时候会发生分区复制，
但是**分区的首领只有一个。**
3. 这种复制机制为分区提供了消息冗余，如果有一个broker失效，其他broker
可以接管领导权。不过相关的消费者和生产者都要重新连接到新的首领。
### 0.4 消息
1. Kafka 的数据单元被称为消息。
2. 消息由字节数组组成，消息里的数据没有特别的格式或含义。
3. 消息可以有一个key，key相同的消息会被写到相同的分区上。
### 0.5 分批传输
1. 为了提高效率，消息被分批写入Kafka。
2. 批次就是一组消息，这些消息属于同一个主题和分区。
3. 在时间延迟和吞吐量之间做trade off：批次越大，单位时间内处理的消息就越多，
单条消息的传输时间就越长。
4. 批次数据会被压缩，提升数据的传输和存储能力，但更耗CPU。
### 0.6 schema
1. 我理解就是序列化方式
2. json和xml虽然可读性好，但是兼容性不是很好
3. Avro好像不错，以后可以研究一下
4. 序列化方式不能随便修改，如果否则生产者和消费者都要同步升级
### 0.7 topic和partition
1. Kafka的消息通过topic进行分类。
2. topic可以被分为若干个partition，一个partition就是一个提交日志。
3. 消息以追加的方式写入分区，然后以FIFO的顺序读取。
4. **由于一个topic一般包含几个分区，因此无法在整个topic范围内保证消息的顺序，
但可以保证消息在单个分区内的顺序。**
5. Kafka通过分区来实现数据冗余和伸缩性。
6. 分区可以分布在不同的服务器上，以此来提升性能。
### 0.8 生产者
1. Kafka的客户端就是Kafka系统的用户，它们被分为**生产者**和**消费者**。
2. 生产者创建消息，一个消息会被发布到一个特定的主题上。
3. 生产者在默认情况下把消息均衡地分布到主题的所有分区上
4. **生产者也可以把消息直接写到指定的分区，通过消息键和分区器来实现，分区器为键生
成一个散列值，并将其映射到指定的分区上。这样可以保证包含同一个键的消息会被写到
同一个分区上。**
5. 生产者也可以使用自定义的分区器，根据不同的业务规则将消息映射到分区。
### 0.9 消费者
1. 消费者读取消息。消费者订阅一个或多个主题，并按照消息生成的顺序读取。
2. 消费者通过检查消息的**偏移量（offset）**来区分已经读取过的消息。 
3. 偏移量（offset）是另一种元数据，它是一个不断递增的整数值，在创建消息
时，Kafka会把它添加到消息里。
4. 在给定的分区中，单条消息的偏移量都是**唯一**的。
5. 消费者把每个分区最后读取的消息偏移量保存在Zookeeper或 Kafka上，
如果消费者关闭或重启，它的读取状态不会丢失。
6. 消费者是消费者群组的一部分，会有一个或多个消费者共同读取一个主题。
7. 群组保证每个分区只能被一个消费者使用。**如果一个消费者失效，
群组里的其他消费者可以接管失效消费者的工作。**

## 1 kafka的优势

### 1.1 多个生产者
1个topic可以有多个生产者，同时发。
### 1.2 多个消费者
多个消费者可以组成一个群组，它们共享一个消息流，并保证整个群组对每个给定的消息
只处理一次。
### 1.3 磁盘存储数据
1. Kafka不仅支持多个消费者，还允许消费者非实时地读取消息。
2. 消息被提交到磁盘，根据设置的保留规则进行保存。
3. 每个主题可以设置单独的保留规则，以便满足不同消费者的需求，
各个主题可以保留不同数量的消息。
4. 消费者可能会因为处理速度慢或突发的流量高峰导致无法及时读取消息，
而持久化数据可以保证数据不会丢失。
5. 消费者可以在进行应用程序维护时离线一小段时间，而无需担心消息丢失或堵
塞在生产者端。
6. 消费者可以被关闭，但消息会继续保留在 Kafka 里。消费者可以从上次中
断的地方继续处理消息。
### 1.4 伸缩性
一个包含多个 broker 的集群，即使个别 broker失效，仍然可以持续地为客户提供服务。
支持随时扩展
### 1.5 高性能
上面提到的所有特性，让 Kafka 成为了一个高性能的发布与订阅消息系统。通过横向扩展
生产者、消费者和 broker， Kafka 可以轻松处理巨大的消息流。在处理大量数据的同时，
它还能保证亚秒级的消息延迟。
## 2 broker配置

### 2.1 broker.id
1. 每个broker都需要有一个标识符，使用broker.id来表示。
2. 一般都是将ID号映射到机器名。
### 2.2 port
1. 如果使用默认配置来启动 Kafka，它会监听 9092 端口。
2. 修改 port 配置参数可以把它设置成其他任意可用的端口。
3. 如果使用 1024 以下的端口，需要使用 root 权限启动Kafka，**别这么干**。
### 2.3 zookeeper.connect
1. 用于保存 broker元数据的Zookeeper地址。
2. 一般都要指定Chroot。
### 2.4 log.dirs
1. Kafka把所有消息都保存在磁盘上，存放这些日志片段的目录是通过 log.dirs 指定的。
2. 它是一组用逗号分隔的本地文件系统路径。
3. 如果指定了多个路径，那么 broker 会根据“最少使用”原则，
把同一个分区的日志片段保存到同一个路径下。
4. 要注意， broker 会往拥有最少数目分区的路径新增分区，
而不是往拥有最小磁盘空间的路径新增分区。
### 2.5 num.recovery.threads.per.data.dir
1. 对于如下 3 种情况， Kafka 会使用可配置的线程池来处理日志片段：
* 服务器正常启动，用于打开每个分区的日志片段；
* 服务器崩溃后重启，用于检查和截短每个分区的日志片段；
* 服务器正常关闭，用于关闭日志片段。
2. 默认情况下，每个日志目录只使用一个线程。
3. 因为这些线程只是在服务器启动和关闭时会用到，所以完全可以设置大量的线程
来达到并行操作的目的。
4. 对于包含大量分区的服务器来说，一旦发生崩溃，在进行恢复时使用并行操作可能
会省下数小时的时间。
5. 设置此参数时需要注意，所配置的数字对应的是 log.dirs 指定的单个日志目录。
也就是说，如果 num.recovery.threads.per.data.dir 被设为 8，
并且 log.dir 指定了 3 个路径，那么总共需要 24 个线程。
### 2.6 auto.create.topics.enable
> **这个参数默认是true，要改为false！**
1. 默认情况下， Kafka 会在如下几种情形下自动创建主题：
* 当一个生产者开始往主题写入消息时；
* 当一个消费者开始从主题读取消息时；
* 当任意一个客户端向主题发送元数据请求时。
2. 这些行为都是非预期的，最好别这么搞，建议把
 auto.create.topics.enable 设为 false。

## 3 主题的默认配置
### 3.1 num.partitions
1. num.partitions 参数指定了新创建的主题将包含多少个分区。
2. 该参数的默认值是 1。
3. **我们可以增加主题分区的个数，但不能减少分区的个数。**
4. 拥有大量消息的主题如果要进行负载分散，就需要大量的分区。
### 3.2 如何选定分区数量
在进行数量选择时，需要考虑如下几个因素:
* 主题需要达到多大的吞吐量？例如，是希望每秒钟写入 100KB 还是 1GB ？
* 从单个分区读取数据的最大吞吐量是多少？每个分区一般都会有一个消费
者，如果你知道消费者将数据写入数据库的速度不会超过每秒 50MB，那
么你也该知道，从一个分区读取数据的吞吐量不需要超过每秒 50MB。
* 可以通过类似的方法估算生产者向单个分区写入数据的吞吐量，不过生产
者的速度一般比消费者快得多，所以最好为生产者多估算一些吞吐量。
* 每个 broker 包含的分区个数、可用的磁盘空间和网络带宽。
* 如果消息是按照不同的键来写入分区的，那么为已有的主题新增分区就会
很困难。
* 单个 broker 对分区个数是有限制的，因为分区越多，占用的内存越多，完
成首领选举需要的时间也越长。

> 如果每秒钟要从主题上写入和读取 1GB 的数据，并且每个消费者每秒钟可以处理
50MB的数据，那么至少需要20个分区。这样就可以让 20 个消费者同时读取这些分区，
从而达到每秒钟 1GB 的吞吐量。

### 3.3 log.retention.ms
1. Kafka 通常根据时间来决定数据可以被保留多久。
2. 默认使用 log.retention.hours 参数来配置时间，默认值为 168 小时，也就是一周。
3. 除此以外，还有其他两个参数 log.retention.minutes 和 log.retention.ms。
这 3 个参数的作用是一样的，都是决定消息多久以后会被删除
5. **推荐使用 log.retention.ms。**
6. 如果指定了不止一个参数，Kafka 会优先使用具有最小值的那个参数。

>根据时间保留数据是通过检查磁盘上日志片段文件的最后修改时间来实现
的。一般来说，最后修改时间指的就是日志片段的关闭时间，也就是文件里
最后一个消息的时间戳。

### 3.4 log.retention.bytes
1. 还可以通过保留的消息字节数来判断消息是否过期，通过参数 log.
retention.bytes 来指定，作用在每一个分区上。
>如果有一个包含 8 个分区的主题，并且 log.retention.bytes 被设为 1GB，
那么这个主题最多可以保留 8GB 的数据。当主题的分区个数增加时，
整个主题可以保留的数据也随之增加。
### 3.5 消息保留策略
1. 如果同时指定了 log.retention.bytes 和 log.retention.ms（或者另一个时
间参数），只要任意一个条件得到满足，消息就会被删除。
> 例如，假设 log.
retention.ms 设置为 86 400 000（也就是 1 天）， log.retention.bytes 设置
为 1 000 000 000（也就是 1GB），**如果消息字节总数在不到一天的时间就超
过了 1GB，那么多出来的部分就会被删除。相反，如果消息字节总数小于
1GB，那么一天之后这些消息也会被删除，尽管分区的数据总量小于 1GB。**

### 3.6 log.segment.bytes
1. 以上的设置都作用在日志片段上，而不是作用在单个消息上。
2. 当消息到达 broker 时，它们被追加到分区的当前日志片段上。
3. 当日志片段大小达到 log.segment.bytes 指定的上限时，当前日志片段就会被关闭，
一个新的日志片段被打开。
4. **只有一个日志片段被关闭后，才会开始等待过期。**
5. 这个参数的值越小，就会越频繁地关闭和分配新文件，从而降低磁盘写入的整体效率。
6. 如果主题的消息量不大，就需要调整这个参数的大小。
>例如，如果一个主题每天只接收 100MB 的消息，而 log.segment.bytes 使用默认设置，
那么需要10天才能填满一个日志片段。**因为在日志片段被关闭之前消息是不会过期的**，
所以如果 log.retention.ms 被设为 604 800 000（也就是 1 周），
那么日志片段最多需要 17 天才会过期。
这是因为关闭日志片段需要 10 天的时间，而根据配置的过期时间，还需要再保留 7 天时
间（**要等到日志片段里的最后一个消息过期才能被删除**）。

### 3.7 log.segment.ms
1. 指定了多长时间之后日志片段会被关闭。
2. log.segment.bytes 和 log.retention.ms看哪个条件先得到满足。
3. log.segment.ms 没有默认设定值，所以只根据大小来关闭日志片段。
4. **基于时间的日志片段对磁盘性能的是有影响的，需要谨慎配置**

> 在使用基于时间的日志片段时，要着重考虑并行关闭多个日志片段对磁盘性
能的影响。如果多个分区的日志片段永远不能达到大小的上限，就会发生这
种情况，因为 broker 在启动之后就开始计算日志片段的过期时间，对于那些
数据量小的分区来说，日志片段的关闭操作总是同时发生。

5. 所以这个值最好别设置

### 3.8 message.max.bytes
1. 此参数来限制单个消息的大小，该参数指的是压缩后的消息大小。
2. 默认值是1MB。
3. 如果生产者尝试发送的消息超过这个大小，不仅消息不会被接收，还会受到报错异常。
4. **这个值对性能有显著的影响。值越大，那么负责处理网络连接和请求的线程就需要
花越多的时间来处理这些请求。它还会增加磁盘写入块的大小，从而影响 IO 吞吐量。**

### 3.9 服务端和客户端之间的消息大小需要协商！
消费者客户端设置的 fetch.message.max.bytes 必须与服务器端设置的消息
大小进行协商。**如果这个值比 message.max.bytes 小，那么消费者就无法读
取比较大的消息，导致出现消费者被阻塞。** 在为集群里的 broker 配置
replica.fetch.max.bytes 参数时，也要注意这个问题！。

>笔者生产上就遇到过这种情况，message.max.bytes设置的比较大，但是客户端设置的
小。当消费者遇到一条大消息会报错，导致那个partition的消息无法消费。这是很严重的
生产事故，一定要小心。**还有，这个问题锅不是我的，我只是帮忙查了这个问题。**

## 4 硬件的选择
### 4.1 磁盘吞吐量
1. 服务器端磁盘吞吐量的影响生产者发送消息的性能。生产者生成的消息必须被提交
到服务器保存，大多数客户端在发送消息之后会一直等待，直到至少有一个服务器确认消
息已经成功提交为止。
2. 磁盘写入速度越快，生成消息的延迟就越低。
3. 有钱上固态，没钱做raid。
### 4.2 磁盘容量
1. 需要多大的磁盘容量取决于需要保留的消息数量。
2. 存储容量的选择同时受到集群复制策略的影响。
>如果服务器每天会收到 1TB 消息，并且保留 7 天，那么就需要 7TB 的存储空间，
而且还要为其他文件提供至少 10% 的额外空间。除此之外，还需要提供缓冲区，
用于应付消息流量的增长和波动。
### 4.3 内存
1. 磁盘性能影响生产者，而内存影响消费者。
2. 消费者一般从分区尾部读取消息，如果有生产者存在，消费者会直接读取存放在
系统的页面缓存中的消息，这比从磁盘上重新读取要快得多。
3. 运行 Kafka 的 JVM 不需要太大的内存，剩余的系统内存可以用作页面缓存，
或者用来缓存正在使用中的日志片段。
4. 不建议把 Kafka 同其他程序部署在1台机器上，它们需要共享页面缓存，
降低消费者的性能。
### 4.4 网络
1. 网络吞吐量决定了 Kafka 能够处理的最大数据流量。
2. 它和磁盘存储是制约 Kafka 扩展规模的主要因素。 
3. Kafka 支持多个消费者，造成流入和流出的网络流量不平衡，从而让情况变
得更加复杂。
4. 集群复制和镜像也会占用网络流量。
5. 如果网络接口出现饱和，那么集群的复制就会出现延时，整个集群都可能会垮掉。
### 4.5 CPU
与磁盘和内存相比， Kafka 对计算处理能力的要求相对较低。
唯一需要CPU的地方就是解压缩客户端的数据流，然后重新压缩，写到本地磁盘。

## 5 kafka集群
### 5.1 集群的优势
1. 可以跨服务器进行负载均衡。
2. 可以使用复制功能来避免因单点故障造成的数据丢失。
3. 在维护 Kafka 或底层系统时，使用集群可以确保为客户端提供高可用性。

### 5.2 需要多少个broker
1. 需要多少磁盘空间来保留数据，以及单个 broker 有多少空间可用。
>如果整个集群需要保留 10TB 的数据，每个broker 可以存储 2TB，
那么至少需要 5 个 broker。如果启用了数据复制，那么至少还需要
一倍的空间，不过这要取决于配置的复制系数是多少。也就是说，如
果启用了数据复制，那么这个集群至少需要 10 个 broker。

2. 集群处理请求的能力。这通常与网络接口处理客户端流量的能力有
关，特别是当有多个消费者存在或者在数据保留期间流量发生波动（比如高峰时段的流量
爆发）时。
### 5.3 broker配置
1. 所有 broker 都必须配置相同的 zookeeper.connect。
2. 每个 broker 都必须为 broker.id 参数设置唯一的值。

>如果两个 broker 使用相同的broker.id，那么第二个 broker 就无法启动。
### 5.4 操作系统调优
>调优的参数主要与虚拟内存、网络子系统和用来存储日志片段的磁盘挂载点有关。
这些参数一般配置在 /etc/sysctl.conf文件里，
不过在对内核参数进行调整时，最好参考操作系统的文档。
#### 5.4.1 虚拟内存
1. 对于大多数依赖吞吐量的应用程序来说，要尽量避免内存交换。
2. 内存页和磁盘之间的交换对 Kafka 各方面的性能都有重大影响。 
3. Kafka 大量地使用系统页面缓存，如果虚拟内存被交换到磁盘，
说明已经没有多余内存可以分配给页面缓存了。
4. 进行内存交换可以防止操作系统由于内存不足而突然终止进程。
5. 建议把 vm.swappiness 参数的值设置得小一点，比如 1。
6. 要优先考虑减小页面缓存，而不是进行内存交换。
>为什么不把 vm.swappiness 设为零
先前，人们建议尽量把 vm.swapiness 设为 0，它意味着“除非发生内存溢
出，否则不要进行内存交换”。直到 Linux 内核 3.5-rc1 版本发布，这个值的
意义才发生了变化。这个变化被移植到其他的发行版上，包括 Red Hat 企业
版内核 2.6.32-303。在发生变化之后， 0 意味着“在任何情况下都不要发生交
换”。所以现在建议把这个值设为 1。

7. 日志片段一般要保存在快速磁盘上，不管是SSD还是Raid。
8. 减少脏页的数量，这个可以通过将 vm.dirty_background_ratio
设为小于 10 的值来实现。该值指的是系统内存的百分比，大部分情况下设为 5 就可以
了。它不应该被设为 0，因为那样会促使内核频繁地刷新页面，从而降低内核为底层设备的
磁盘写入提供缓冲的能力。
通过设置 vm.dirty_ratio 参数可以增加被内核进程刷新到磁盘之前的脏页数量，
可以将它设为大于 20 的值（这也是系统内存的百分比）。这个值可设置的范围很广，
60~80 是个比较合理的区间。不过调整这个参数会带来一些风险，
包括未刷新磁盘操作的数量和同步刷新引起的长时间 I/O 等待。
**如果该参数设置了较高的值，建议启用 Kafka 的复制功能，避免因系统崩溃造
成数据丢失。**
9. 为了给这些参数设置合适的值，最好是在 Kafka 集群运行期间检查脏页的数量，
不管是在生存环境还是模拟环境。
可以在 /proc/vmstat 文件里查看当前脏页数量。
```
# cat /proc/vmstat | egrep "dirty|writeback"
nr_dirty 3875
nr_writeback 29
nr_writeback_temp 0
#
```
#### 5.4.2 磁盘
1. 文件系统是影响性能的另一个重要因素。
2. EXT4和XFS最为常见。
3. XFS 为Kafka提供了更好的性能，除了由文件系统提供的自动调优之外，无需额外的调优。批量
磁盘写入具有更高的效率，可以提升整体的 I/O 吞吐量。
4. 不管使用哪一种文件系统，都要对挂载点的 noatime 参数进行合理的设置。
5. 文件元数据包含3个时间戳：
 	* 创建时间（ctime）
 	* 最后修改时间（mtime）
 	* 最后访问时间（atime）。
默认情况下，每次文件被读取后都会更新 atime，这会导致大量的磁盘写操作，
而且 atime 属性的用处不大，所以完全可以把它禁用掉。
6. 为挂载点设置 noatime 参数可以防止更新 atime，但不会影响 ctime 和 mtime。

#### 5.4.3 网络
1. 调整Kafka 的网络配置与调整其他大部分 Web 服务器和网络应用程序的网络配置是一样的。
2. 对分配给 socket 读写缓冲区的内存大小作出调整，可以显著提升网络的传输性能。
3. socket读写缓冲区对应的参数是：
	* net.core.wmem_default(一般设置128K)
	* net.core.rmem_default(一般设置128K)

4. socket读写缓冲区最大值的参数是：
	* net.core.wmem_max(一般设置2MB)
	* net.core.rmem_max(一般设置2MB)
5. 还需要设置 TCP socket 的读写缓冲区，参数分别是：
	* net.ipv4.tcp_wmem
	* net.ipv4.tcp_rmem。
这些参数的值由 3 个整数组成，它们使用空格分隔，分别表示最小值、默认值和最大值。
最大值不能大于 net.core.wmem_max 和 net.core.rmem_max指定的大小。
>这些参数需要根据kafka接收的数据进行调整

6. 还有其他一些有用的网络参数：
	* net.ipv4.tcp_window_scaling 设为 1，启用 TCP时间窗扩展，可以提升客户端传输数据的效率，传输的数据可以在服务器端进行缓冲。
	* 把net.ipv4.tcp_max_syn_backlog 设为比默认值 1024 更大的值，可以接受更多的并发连接。
	* 把net.core.netdev_max_backlog 设为比默认值 1000 更大的值，有助于应对网络流量的爆
发，特别是在使用千兆网络的情况下，允许更多的数据包排队等待内核处理。

## 6 生产环境的注意事项
### 6.1 GC回收器的选择
1. kafka的回收器推荐使用G1，只需要很少的配置就能很好地工作。
2. 以下是 G1 的两个调整参数。
	* MaxGCPauseMillis：
	该参数指定每次垃圾回收默认的停顿时间。该值不是固定的， G1 可以根据需要使用更
	长的时间。它的默认值是 200ms。也就是说， G1 会决定垃圾回收的频率以及每一轮需
	要回收多少个区域，这样算下来，每一轮垃圾回收大概需要 200ms 的时间。
	* InitiatingHeapOccupancyPercent：
	该参数指定了在 G1 启动新一轮垃圾回收之前可以使用的堆内存百分比，默认值是 45。
	也就是说，在堆内存的使用率达到 45% 之前， G1 不会启动垃圾回收。这个百分比包括
	新生代和老年代的内存。
3. Kafka 对堆内存的使用率非常高，容易产生垃圾对象，可以把这些值设得小一些。

>如果一台服务器有 64GB 内存，并且使用 5GB 堆内存来运行 Kafka，那么可以参考以下的配
置： MaxGCPauseMillis 可以设为 20ms； InitiatingHeapOccupancyPercent 可以设为 35，这
样可以让垃圾回收比默认的要早一些启动。

4. Kafka 的启动脚本并没有启用 G1 回收器，而是使用了 Parallel New 和 CMS垃圾回收器,
记得改。
### 6.2 数据中心的部署
一句话，多个broker要部署在不同的机器上，这些机器最好处于不同的网络分区，电源等等，否则
还是存在单点故障问题。
### 6.3 共享zookeeper
1. Kafka 使用 Zookeeper 来保存 broker、主题和分区的元数据信息。
2. 不要让多套kafka集群共享同一个zookeeper集群。
3. 要使用0.9.0.1以后的kafka，这样消费者提交offset是向kafka broker提交的，否则是向
zookeeper提交，会对zk集群造成不小的压力。

## 7 kafka生产者

### 7.1 概览
1. ProducerRecord包含四个属性：
	* Topic
	* Partition
	* key
	* Value
2. 如果ProducerRecord有partition，就向指定的分区发送消息；
如果没有partition，就使用key字段选择一个分区。
3. 这条记录会被添加到一个批次里面，会有独立的线程负责将批次发送到相应的broker上。
4. 如果发送成功，就返回RecordMetaData，否则就尝试重发，如果重发还是失败，就返回
错误信息。

### 7.2 消息发送方式
#### 7.2.1 同步发送
调用send方法会返回一个Future对象，调用Future的get方法判断是否发送成功。
#### 7.2.2 异步发送
需要一个实现了 org.apache.kafka.clients.producer.Callback 接口的
类，这个接口只有一个 onCompletion 方法。

### 7.3 生产者的配置

#### 7.3.1 acks
acks参数指定了必须要有多少个分区副本收到消息，生产者才会认为消息写入是成功的。

* acks=0：吞吐量最高，生产者不会等服务器的响应
* acks=1：吞吐量会下降，kafka集群leader的收到消息，生产者就认为发送成功。这种情况还是
会丢消息，kafka leader 收到消息不会直接写入磁盘，而是存入缓冲区，如果此时服务挂掉
，消息就丢失了。
* acks=all：吞吐量最低，最安全，不会丢消息，但是延迟最高。

#### 7.3.2 buffer.memory
生产者发送缓冲区，producer使用这个缓冲区缓冲要发送到服务器的消息，如果缓冲区
满了说明应用程序向生产者发的太快了，大于生产者实际发送至服务器的速度。此时，
send() 方法调用要么被阻塞，要么抛出异常。

#### 7.3.3 compression.type
1. 默认情况下，消息发送时不会被压缩。
2. 该参数可以设置为：
	* snappy: Google发明的一种性价比高的压缩算法，占用较少的CPU，也能提供不错的压缩比
	* gzip: CPU消耗大，压缩比最高
	* lz4: 不知道

>使用压缩可以降低网络传输开销和存储开销，极大地提高kafka性能。

#### 7.3.4 retries
1. retries参数的值决定了生产者在发送失败时可以重发消息的次数。
2. 如果达到这个次数，生产者会放弃重试并返回错误。
3. 默认情况下，生产者会在每次重试之间等待 100ms，不过可以通过retry.backoff.ms 参数来修改。

>建议在设置重试次数和重试时间间隔之前，
先测试一下恢复一个崩溃节点需要多少时间（比如所有分区选举出首领需要多长时间），
让总的重试时间比 Kafka 集群从崩溃中恢复的时间长，否则生产者会过早地放弃重试。不
过有些错误不是临时性错误，没办法通过重试来解决（比如“消息太大”错误）。

#### 7.3.5 batch.size
1. 当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。
2. 该参数指定了一个批次可以使用的内存大小，按照字节数计算。
3. 当批次被填满或者到了时间间隔(linger.ms)，批次里的所有消息会被发送出去。
4. 这个值设的打，只是会占用更多的内存，不会增加延迟。设置得太小，需要更频繁地发送消息，会增加网络开销。

#### 7.3.6 linger.ms
1. linger.ms设置成比0大的数，让生产者在发送批次之前等待一小会儿，使更多的消息加入到这个批次。
2. 消息打包发送会增加延迟，但会提升吞吐量。

#### 7.3.7 client.id
1. 该参数可以是任意的字符串，服务器会用它来识别消息的来源。

#### 7.3.8 max.in.flight.requests.per.connection
1. 该参数指定了生产者在收到服务器响应之前可以发送多少个消息。它的值越高，就会占用
越多的内存，不过也会提升吞吐量。
2. **把它设为1可以保证消息是按照发送的顺序写入服务器的，即使发生了重试。**

#### 7.3.9  timeout.ms、 request.timeout.ms 和 metadata.fetch.timeout.ms
1. request.timeout.ms 
指定了生产者在发送数据时等待服务器返回响应的时间
2. metadata.fetch.timeout.ms
指定了生产者在获取元数据（比如目标分区的首领是谁）时等待服务器返回响应的时间。 
3. timeout.ms
指定了 broker 等待同步副本返回消息确认的时间，**与asks的配置相匹配——如果在指定时间内没有收到同步副本的确认**，那么 broker 就会返回一个错误。

#### 7.3.10 max.block.ms
1. 该参数指定了在调用 send() 方法或使用 partitionsFor() 方法获取元数据时生产者的阻塞
时间。
2. 当生产者的发送缓冲区已满，或者没有可用的元数据时，这些方法就会阻塞。在阻
塞时间达到 max.block.ms 时，生产者会抛出超时异常。

#### 7.3.11 max.request.size
1. 生产者发送的请求大小。
2. 它可以指能发送的单个消息的最大值，也可以指单个请求里所有消息总的大小。
> 例如，假设这个值为 1MB， 那么可以发送的单个最大消
息为 1MB，或者生产者可以在单个请求里发送一个批次，该批次包含了 1000 个消息，每
个消息大小为 1KB。
3. broker可接收的消息最大值也有的限制（message.max.bytes）。

#### 7.3.12 receive.buffer.bytes 和 send.buffer.bytes
1. 这两个参数分别指定了 TCP socket 接收和发送数据包的缓冲区大小。
2. 如果它们被设为 -1，就使用操作系统的默认值。
3. 如果生产者或消费者与 broker处于不同的数据中心，那么可以
适当增大这些值，因为跨数据中心的网络一般都有比较高的延迟和比较低的带宽。

#### 7.3.13 如何保证kafka消息绝对有序
Kafka可以保证同一个分区里的消息是有序的。也就是说，如果生产者按照
一定的顺序发送消息，broker就会按照这个顺序把它们写入分区，消费者也
会按照同样的顺序读取它们。在某些情况下，顺序是非常重要的。例如，往
一个账户存入 100 元再取出来，这个与先取钱再存钱是截然不同的！不过，
有些场景对顺序不是很敏感。
如果把 retries 设为非零整数，同时把 max.in.flight.requests.per.connection
设为比 1 大的数，那么，如果第一个批次消息写入失败，而第二个批次写入
成功， broker 会重试写入第一个批次。如果此时第一个批次也写入成功，那
么两个批次的顺序就反过来了。
一般来说，如果某些场景要求消息是有序的，那么消息是否写入成功也是
很关键的，所以不建议把 retries 设为 0。可以把 max.in.flight.requests.
per.connection 设为 1，这样在生产者尝试发送第一批消息时，就不会有其
他的消息发送给 broker。不过这样会严重影响生产者的吞吐量，所以只有在
对消息的顺序有严格要求的情况下才能这么做。

### 7.4 序列化器
不详细说了
### 7.5 分区
1. 使用相同的key可以将kafka消息指定到同一个partition。
2. 可以使用自定义分区实现多种分布式事务的局部有序：
	* 如果某个事务需要争抢全局资源(扣一个总额度)，需要全局有序。
	* 如果不需要争抢全局资源，只考虑局部有序即可。
   
 ** 使用自定义的分区器，判断当前消息是否是争抢型，如果是总是将其存到第一个partition。
   如果不是，只要根据key散列一个partition即可 **。

## 8 消费者
### 8.1 消费者消费者群组
1. 单线程消费肯定不够的，所以有消费者群组这个概念。
2. 假如一个topic有24个partition，
可以设置一个消费者群组group1，包含24个消费者，每个消费者消费一个partition。
然后再搞一个group2，包含10个消费者，对数据做一些日志记录。

3. 同一个topic，可以有多个group消费，多个group之间消费进度互不干涉。
4. 如果消费者数量小于partition数量，那么有的消费者会消费多个partition。
5. 如果消费者数量大于partition数量，那么有的消费者会闲置。
### 8.2 rebalance
1. 消费者调用poll方法从kafka拉取消息，这个方法也包含了心跳。
2. 两次poll方法调用必须小于超时时间，否则，kafka认为消费者宕机，会触发一次rebalance。
3. 发生rebalance是应该尽量避免的，不过它也是一种高可用的手段。

### 8.3 创建消费者
1. 设置属性
```
Properties props = new Properties();
props.put("bootstrap.servers", "broker1:9092,broker2:9092");
props.put("group.id", "CountryCounter");
props.put("key.deserializer",
"org.apache.kafka.common.serialization.StringDeserializer");
props.put("value.deserializer",
"org.apache.kafka.common.serialization.StringDeserializer");
KafkaConsumer<String, String> consumer = new KafkaConsumer<String,
String>(props);
```
2. 订阅主题
` consumer.subscribe(Collections.singletonList("customerCountries")); `
3. 拉取数据并处理
```
try {
while (true) { 
ConsumerRecords<String, String> records = consumer.poll(100); 
for (ConsumerRecord<String, String> record : records) 
{
log.debug("topic = %s, partition = %s, offset = %d, customer = %s,
country = %s\n",
record.topic(), record.partition(), record.offset(),
record.key(), record.value());
int updatedCount = 1;
if (custCountryMap.countainsValue(record.value())) {
updatedCount = custCountryMap.get(record.value()) + 1;
}
custCountryMap.put(record.value(), updatedCount)
JSONObject json = new JSONObject(custCountryMap);
System.out.println(json.toString(4)) 
}
}
} finally {
consumer.close(); 
}
```
4. 每个消费者都要使用独立的线程去消费数据

### 8.4 消费者配置

#### 8.4.1 fetch.min.bytes
1. 消费者从服务器获取记录的最小字节数。
2. broker在收到消费者的数据请求时，如果可用的数据量小于 fetch.min.bytes 指定的大小，那么它会等到有足够的可用数据时才把它返回给消费者。
3. 把该属性的值设置得大一点可以降低broker的压力。
4. 消费者如果拉不到消息，说明消息太少，此时消费者这边可以Thread.sleep一段时间再去拉取，当然sleep时间要小于超时时间。

#### 8.4.2 fetch.max.wait.ms
一句话，如果`fetch.max.wait.ms`被设为 100ms，并且 fetch.min.bytes 被设为 1MB，那么 Kafka 在收到消费者的请求后，要么返回1MB数据，要么在100ms后返回所有可用的数据，就看哪个条件先得到满足。
#### 8.4.3 max.partition.fetch.bytes
1. 该属性指定了服务器从每个分区里返回给消费者的最大字节数。
2. 默认值是 1MB。
3. 这个值是需要权衡的，太大就处理不完，导致消费者无法及时发起第二次轮询，这样两次轮询
时间间隔很可能超时，会触发rebalance。

#### 8.4.4 auto.offset.reset
1. 该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下该作何处理。
2. 它的默认值是 latest，消费者将从最新的记录开始读取数据。
3. 另一个值是 earliest，消费者将从起始位置读取分区的记录。

>个人认为如果做了幂等，erliest比较好。

#### 8.4.5 enable.auto.commit
1. 该属性指定了消费者是否自动提交偏移量，默认值是 true。
2. 建议设为false，由自己控制何时提交偏移量。
3. 如果设为true，还可以通过配置 auto.commit.interval.ms属性来控制提交的频率。

#### 8.4.6 partition.assignment.strategy
这个参数指定了分区策略
1. org.apache.kafka.clients.consumer.RangeAssignor：该策略会把主题的若干个连续的分区分配给消费者。
2. org.apache.kafka.clients.consumer.RoundRobinAssignor：该策略把主题的所有分区逐个分配给消费者。
3. 也可以使用自定义类。

> 针对一些核心的业务，可以将分区和消费都事先规划好。

#### 8.4.7  client.id
该属性可以是任意字符串，broker用它来标识从客户端发送过来的消息。

#### 8.4.8 max.poll.records
该属性用于控制单次调用 call() 方法能够返回的记录数量，可以帮你控制在轮询里需要处
理的数据量。

#### 8.4.9 receive.buffer.bytes 和 send.buffer.bytes
和生产者的属性是一个意思。

### 8.5 提交和偏移量
更新分区已消费位置的操作叫作**提交**。
#### 8.5.1 消费者如何提交偏移量
消费者往一个叫作 _consumer_offset 的特殊主题发送消息，消息里包含每个分区的偏移量。
#### 8.5.2 重复消费和消息丢失
1. 如果消费者还没来得及提交偏移量就挂了，系统会触发一次rebalance，新消费者会
从系统记录的偏移量继续消费，之前有一部分消息就被重复消费了。
2. 如果消费者先提交偏移量再处理消息，此时消费者挂掉，系统触发rebalance后，新的
消费者读取的偏移量跳过了之前的消息，那些消息就不会被处理了，也就是丢消息。
#### 8.5.3 自动提交
1. 如果enable.auto.commit被设为true，那么每过 5s，消费者会自动把从poll()方法接收到的最大偏移量提交上去。
2. 提交时间间隔由auto.commit.interval.ms控制，默认值是 5s。
3. 使用自动提交时，如果出现了rebalance，消息一定会被重复消费，无法避免，要做幂等！

#### 8.5.4 同步提交
1. auto.commit.offset 设为 false，让应用程序决定何时提交偏移量。
2. 使用 commitSync()提交偏移量最简单也最可靠。
3. 这个 API 会提交由 poll() 方法返回的最新偏移量，提交成功后马上返回，如果提交失败就抛出异常。

>在一些核心业务场景中，使用手动提交是最稳妥的，因为核心业务一般吞吐量是第二考虑的，
首先要考虑的问题是业务不能出错，在一些银行业务中，宁可整个服务宕机几小时，也不能
让数据出错。
#### 8.5.5 异步提交
1. consumer.commitAsync()异步提交，不会阻塞消费者。
>如果现在有两次异步提交，第一次异步提交offset2000失败，第二次异步提交3000成功，
稍后第一个提交2000又成功了，此时如果触发了rebalance，会导致2000~3000这部分数据
被重复消费。
2. commitAsync支持回调。

>我们可以使用一个单调递增的序列号来维护异步提交的顺序。在每次提交偏
移量之后或在回调里提交偏移量时递增序列号。在进行重试前，先检查回调
的序列号和即将提交的偏移量是否相等，如果相等，说明没有新的提交，那
么可以安全地进行重试。如果序列号比较大，说明有一个新的提交已经发送
出去了，应该停止重试。
#### 8.5.6 同步和异步组合式提交
```
try {
while (true) {
ConsumerRecords<String, String> records = consumer.poll(100);
for (ConsumerRecord<String, String> record : records) {
System.out.println("topic = %s, partition = %s, offset = %d,
customer = %s, country = %s\n",
record.topic(), record.partition(),
record.offset(), record.key(), record.value());
}
consumer.commitAsync(); ➊
}
} catch (Exception e) {
log.error("Unexpected error", e);
} finally {
try {
consumer.commitSync(); ➋
} finally {
consumer.close();
}
}
➊	如果一切正常，我们使用 commitAsync() 方法来提交。这样速度更快，而且即使这次提
交失败，下一次提交很可能会成功。
➋	如果直接关闭消费者，就没有所谓的“下一次提交”了。使用 commitSync() 方法会一
直重试，直到提交成功或发生无法恢复的错误。
```

#### 8.5.7 提交特定的offset值
```
private Map<TopicPartition, OffsetAndMetadata> currentOffsets =
new HashMap<>(); ➊
int count = 0;
...
while (true) {
ConsumerRecords<String, String> records = consumer.poll(100);
for (ConsumerRecord<String, String> record : records)
{
System.out.printf("topic = %s, partition = %s, offset = %d,
customer = %s, country = %s\n",
record.topic(), record.partition(), record.offset(),
record.key(), record.value()); ➋
currentOffsets.put(new TopicPartition(record.topic(),
record.partition()), new
OffsetAndMetadata(record.offset()+1, "no metadata")); ➌
if (count % 1000 == 0) ➍
consumer.commitAsync(currentOffsets,null); ➎
count++;
}
}
➊	用于跟踪偏移量的 map。
➋	记住， printf 只是处理消息的临时方案。
➌	在读取每条记录之后，使用期望处理的下一个消息的偏移量更新 map 里的偏移量。下
一次就从这里开始读取消息。
➍	我们决定每处理 1000 条记录就提交一次偏移量。在实际应用中，你可以根据时间或记
录的内容进行提交。
	这里调用的是 commitAsync()，不过调用 commitSync() 也是完全可以的。当然，在提交
特定偏移量时，仍然要处理可能发生的错误。
```
#### 8.5.8 RebalanceListener
创建消费者时可以传一个RebalanceListener的实现类，这样触发rebalance时你可以做一些
处理。
#### 8.5.9 从指定的offset开始处理记录
使用seekTobegining方法。
#### 8.5.10 退出消费者
在另一个线程中调用consumer.wakeUp()方法，能够优雅退出循环。

## 9 深入kafka
### 9.1 集群成员关系
kafka使用zookeeper做集群管理，就是临时节点和watcher那一套，不多说了。
### 9.2 控制器
控制器其实就是一个 broker，只不过它除了具有一般 broker 的功能之外，还负责分区
首领的选举。
#### 使用zk实现的master选主
1. 集群里第一个启动的broker在Zk里创建一个临时节点/controller让自己成为控制器。
2. 其他broker在启动时也会尝试创建这个节点，不过会创建失败。
3. 其他broker在/controller节点上做监听。
4. 如果主节点挂了，从节点会收到通知再执行一遍步骤1。
5. 每个新选出的控制器通过 Zookeeper 的条件递增操作获得一个全新的、数值更大的 controller epoch。
6. 其他broker在知道当前controller epoch后，会忽略旧的epoch消息。
7. epoch是递增的，所以能够避免脑裂问题。

### 9.3 复制








